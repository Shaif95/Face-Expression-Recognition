{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of new",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqFfSOeRPXZwLuqoBqcOWn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8986e0b1cae540559c6648ccffc58c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52e7df7a292b4a7c88cd9092ceea759f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_101fd3a8856f45988e6f2e506ea9e961",
              "IPY_MODEL_9a3527b8f3834374ac9bbaeef67c7c57"
            ]
          }
        },
        "52e7df7a292b4a7c88cd9092ceea759f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "101fd3a8856f45988e6f2e506ea9e961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3649d5c0225b4899be3441cf4b6df88e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 30,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 30,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bd290dc640548779360c5dc7d4ab24f"
          }
        },
        "9a3527b8f3834374ac9bbaeef67c7c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe9c3c3e7e5a4c57ac18b98a31b1c57e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30/30 [04:18&lt;00:00,  8.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3a064da1474435bbb5bd9880d69e8fb"
          }
        },
        "3649d5c0225b4899be3441cf4b6df88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bd290dc640548779360c5dc7d4ab24f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe9c3c3e7e5a4c57ac18b98a31b1c57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3a064da1474435bbb5bd9880d69e8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaif95/Face-Expression-Recognition/blob/main/Copy_of_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37i6xEUJxXdV",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e713a86b-e270-4ede-cdd9-75900abeb147"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3779b8e5-9f25-401e-91ac-fbbf0165024b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3779b8e5-9f25-401e-91ac-fbbf0165024b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Desktop.zip to Desktop.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JchBzT3kxdYd"
      },
      "source": [
        "#!unzip Desktop.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "J2H6MnZudg6z",
        "outputId": "206ee8c4-78a1-478f-ff53-268ba28df0e6"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a0b3e364-d539-45cd-bc63-92f71eae3160\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a0b3e364-d539-45cd-bc63-92f71eae3160\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.zip to data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A6RlGW5dhJQ"
      },
      "source": [
        "#!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhRmwX3md6nc",
        "outputId": "2ca513c4-d984-40ed-8858-e2e033733815"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from PIL import Image\n",
        "import re\n",
        "s=\"train\"\n",
        "def key_func(s, _nsre=re.compile('([0-9]+)')):\n",
        "    return [\n",
        "        int(text)\n",
        "        if text.isdigit() else text.lower()\n",
        "        for text in _nsre.split(s)]\n",
        "\n",
        "images = []\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_exp/Ang/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    images.append(n)\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_exp/Dis/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    images.append(n)\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_exp/Hap/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    images.append(n)\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_exp/Sad/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    images.append(n)\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_exp/Sup/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    images.append(n)\n",
        "\n",
        "n= len(images)\n",
        "a = []\n",
        "for i in range (n) :\n",
        "    a.append(cv2.resize(images[i], dsize=(28,28), interpolation=cv2.INTER_CUBIC))\n",
        "\n",
        "X_train = np.array(a)\n",
        "\n",
        "x_train = np.zeros(X_train.shape[:-1])\n",
        "for i in range(X_train.shape[0]): \n",
        "    x_train[i] = cv2.cvtColor(X_train[i], cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "image = []\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_nu/Ang_Nu/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    image.append(n)\n",
        "\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_nu/Dis_Nu/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    image.append(n)\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_nu/Hap_Nu/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    image.append(n)\n",
        "\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_nu/Sad-Nu/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    image.append(n)\n",
        "\n",
        "for img in sorted(glob.glob(\"data/\"+s+\"_nu/Sup_Nu/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    image.append(n)\n",
        "\n",
        "n= len(image)\n",
        "\n",
        "b = []\n",
        "\n",
        "for i in range (n) :\n",
        "    b.append(cv2.resize(image[i], dsize=(28,28), interpolation=cv2.INTER_CUBIC))\n",
        "X_train2 = np.array(b)\n",
        "\n",
        "x_res = np.zeros(X_train2.shape[:-1])\n",
        "for i in range(X_train2.shape[0]): \n",
        "    x_res[i] = cv2.cvtColor(X_train2[i], cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(x_res))\n",
        "print(np.shape(x_train[0]))\n",
        "print(np.shape(x_res[0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(460, 28, 28)\n",
            "(460, 28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u32uswEpcwDQ",
        "outputId": "0a27f849-4003-4b86-ba2f-17ec0b214a44"
      },
      "source": [
        "\n",
        "\n",
        "images = []\n",
        "for img in sorted(glob.glob(\"train_ex/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    images.append(n)\n",
        "\n",
        "\n",
        "n= len(images)\n",
        "a = []\n",
        "for i in range (n) :\n",
        "    a.append(cv2.resize(images[i], dsize=(28,28), interpolation=cv2.INTER_CUBIC))\n",
        "\n",
        "X_train = np.array(a)\n",
        "\n",
        "\n",
        "x_train1 = np.zeros(X_train.shape[:-1])\n",
        "for i in range(X_train.shape[0]): \n",
        "    x_train1[i] = cv2.cvtColor(X_train[i], cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "\n",
        "image = []\n",
        "for img in sorted(glob.glob(\"train_nu/*.jpg\")):\n",
        "    n= cv2.imread(img)\n",
        "    image.append(n)\n",
        "\n",
        "\n",
        "n= len(image)\n",
        "\n",
        "b = []\n",
        "for i in range (n) :\n",
        "    b.append(cv2.resize(image[i], dsize=(28,28), interpolation=cv2.INTER_CUBIC))\n",
        "X_train2 = np.array(b)\n",
        "\n",
        "x_res1 = np.zeros(X_train2.shape[:-1])\n",
        "for i in range(X_train2.shape[0]): \n",
        "    x_res1[i] = cv2.cvtColor(X_train2[i], cv2.COLOR_BGR2GRAY) \n",
        "\n",
        "print(np.shape(x_train1))\n",
        "print(np.shape(x_res1))\n",
        "print(np.shape(x_train1[0]))\n",
        "print(np.shape(x_res1[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4446, 28, 28)\n",
            "(4446, 28, 28)\n",
            "(28, 28)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMno0-HbcyJb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgYLF8F-xdbZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW-z0UIQx5QF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjZL2VSJcXXR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dLh9GTLcYpo",
        "outputId": "490d0be9-e67a-4bed-b9e4-0e9ac3b64c64"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train),784))\n",
        "x_res = x_res.astype('float32') / 255.\n",
        "x_res = np.reshape(x_res, (len(x_res),784))\n",
        "x_train1 = x_train1.astype('float32') / 255.\n",
        "x_train1 = np.reshape(x_train1, (len(x_train1),784))\n",
        "x_res1 = x_res1.astype('float32') / 255.\n",
        "x_res1 = np.reshape(x_res1, (len(x_res1),784))\n",
        "\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(x_res))\n",
        "\n",
        "print(np.shape(x_train1))\n",
        "print(np.shape(x_res1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(460, 784)\n",
            "(460, 784)\n",
            "(4446, 784)\n",
            "(4446, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXCdua0fn9Dx",
        "outputId": "8188a520-4e5e-48cc-b54d-b446fa4d0680"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_res = x_res.astype('float32') / 255.\n",
        "\n",
        "x_train1 = x_train1.astype('float32') / 255.\n",
        "x_res1 = x_res1.astype('float32') / 255.\n",
        "\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(x_res))\n",
        "\n",
        "print(np.shape(x_train1))\n",
        "print(np.shape(x_res1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(460, 28, 28)\n",
            "(460, 28, 28)\n",
            "(4446, 28, 28)\n",
            "(4446, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OfIAxgy-SqG",
        "outputId": "8fd0f3a4-a70c-4582-e7ce-bab7ad5400cc"
      },
      "source": [
        "\n",
        "x_train = np.concatenate([(x_res), x_train])\n",
        "print(np.shape(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(920, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afhplKfpfC54",
        "outputId": "0a7cf28d-cac1-4f9a-c570-b4233eddacb4"
      },
      "source": [
        "\n",
        "x_train1 = np.concatenate([(x_res1), x_train1])\n",
        "print(np.shape(x_train1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8892, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75ENQ63zw6CL",
        "outputId": "d62f1038-aade-403e-f1ed-690bdb2801b9"
      },
      "source": [
        "pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.32.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=8264f8834a81d5050b70a2ac34657dc460f264c014637589de361a26c3930de0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkSQiF9rYTe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a00ec8f-e686-4f25-95de-f317c24983fb"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras as k\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import seaborn as sns\n",
        "from importlib import reload\n",
        "\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "print(tf.executing_eagerly())\n",
        "\n",
        "print(tf.__version__)\n",
        "print(k.__version__)\n",
        "print(tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "1.15.0\n",
            "2.2.4-tf\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8uK9Xu0uCy8"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "LATENT_DIM = 32\n",
        "SIZE = 28\n",
        "NUM_CHANNELS = 1\n",
        "LR = 0.0001\n",
        "BETA = 1.\n",
        "GAMMA = 1."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Zvp3kqrY3z"
      },
      "source": [
        "\n",
        "### loading mnist data\n",
        "#(train_images, y_train), (test_images, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = x_train1.reshape((-1,28,28,1)).astype('float32')\n",
        "test_images = x_train.reshape((-1,28,28,1)).astype('float32')\n",
        "train_images /= 255.\n",
        "test_images /= 255.\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(500).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(500).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVKmjRWJt9hS"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras as k\n",
        "\n",
        "def make_model(SIZE=28, LATENT_DIM=10, BETA=1., GAMMA=1.):\n",
        "\n",
        "    def sample(inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        epsilon = tf.random.normal(shape=(batch, LATENT_DIM))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "    \n",
        "    # Encoder\n",
        "    encoder_inputs = layers.Input(shape=(SIZE, SIZE, 1), name='encoder_input')\n",
        "    e = layers.Conv2D(filters=8,kernel_size=5,padding='SAME',activation='relu',strides=(2,2))(encoder_inputs)\n",
        "    e = layers.BatchNormalization()(e)\n",
        "    e = layers.Conv2D(filters=16,kernel_size=5,padding='SAME',activation='relu',strides=(2,2))(e)\n",
        "    e = layers.BatchNormalization()(e)\n",
        "    e = layers.Flatten()(e)\n",
        "    z_mean = layers.Dense(LATENT_DIM, name='z_mean')(e)\n",
        "    z_log_var = layers.Dense(LATENT_DIM, name='z_log_var')(e)\n",
        "    encoder = k.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var], name='encoder')\n",
        "    \n",
        "    \n",
        "    # Decoder\n",
        "    decoder_inputs = layers.Input(shape=(LATENT_DIM,), name='decoder_input')\n",
        "    d = layers.Dense(units=7*7*8,activation='relu')(decoder_inputs)\n",
        "    d = layers.Reshape((7,7,8))(d)\n",
        "    d = layers.Conv2DTranspose(filters=16,kernel_size=4,strides=(2, 2), padding=\"SAME\", activation='relu')(d)\n",
        "    d = layers.Conv2DTranspose(filters=32,kernel_size=4,strides=(2, 2), padding=\"SAME\", activation='relu')(d)\n",
        "    decoded = layers.Conv2DTranspose(filters=1, kernel_size=3,strides=(1, 1), padding=\"SAME\")(d)\n",
        "    decoder = k.Model(inputs=decoder_inputs, outputs=decoded, name='decoder')\n",
        "    \n",
        "    \n",
        "    # GAN Discriminator\n",
        "    discriminator_input = layers.Input(shape=(SIZE, SIZE, 1), name='discriminator_input')\n",
        "    p = layers.Conv2D(filters=8,kernel_size=5,padding='SAME',activation='relu',strides=(2,2))(discriminator_input)\n",
        "    p = layers.BatchNormalization()(p)\n",
        "    p = layers.Conv2D(filters=16,kernel_size=5,padding='SAME',activation='relu',strides=(2,2))(p)\n",
        "    p = layers.BatchNormalization()(p)\n",
        "    p = layers.Flatten()(p)\n",
        "    out = layers.Dense(1, name='discriminator_out')(p)\n",
        "    discriminator = k.Model(inputs=discriminator_input, outputs=[out,p] , name='discriminator')\n",
        "    \n",
        "    \n",
        "    sampler = layers.Lambda(sample)\n",
        "    vae = k.Model(inputs=encoder_inputs, outputs=decoder(sampler([z_mean, z_log_var])), name='vae')\n",
        "\n",
        "    \n",
        "    def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "        log2pi = tf.math.log(2. * np.pi)\n",
        "        return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
        "    \n",
        "    \n",
        "    def calculate_loss(x):\n",
        "        z_p = tf.random.normal(shape=(tf.shape(x)[0],LATENT_DIM))\n",
        "        z_mean, z_log_var = encoder(x)\n",
        "        z = sample([z_mean, z_log_var])\n",
        "        out = decoder(z)\n",
        "        x_p = decoder(z_p)\n",
        "        dis_x_p, dis_x_p_feat = discriminator(x_p)\n",
        "        dis_x, dis_x_feat = discriminator(x)\n",
        "        dis_x_tilde , dis_x_tilde_feat = discriminator(out)\n",
        "\n",
        "        # kl loss\n",
        "        logpz = log_normal_pdf(z, 0., 0.)\n",
        "        logqz_x = log_normal_pdf(z, z_mean, z_log_var)\n",
        "        kl_loss = tf.reduce_mean(logqz_x - logpz)\n",
        "\n",
        "        \n",
        "        # gaussian perceptual loss as reconstruction loss\n",
        "        reconstruction_loss = -tf.reduce_mean(log_normal_pdf(dis_x_feat, dis_x_tilde_feat, tf.zeros_like(dis_x_tilde_feat)))\n",
        "        \n",
        "\n",
        "        # gan loss\n",
        "        cross_entropy = k.losses.BinaryCrossentropy(from_logits=True)\n",
        "        g_fake = cross_entropy(tf.ones_like(dis_x_tilde), dis_x_tilde)\n",
        "        g_fake_p = cross_entropy(tf.ones_like(dis_x_p), dis_x_p)\n",
        "        d_real = cross_entropy(tf.ones_like(dis_x), dis_x)\n",
        "        d_fake = cross_entropy(tf.zeros_like(dis_x_tilde), dis_x_tilde)\n",
        "        d_fake_p = cross_entropy(tf.zeros_like(dis_x_p), dis_x_p)\n",
        "\n",
        "        return BETA*kl_loss , GAMMA*reconstruction_loss , g_fake + g_fake_p, d_fake + d_fake_p + d_real\n",
        "        \n",
        "    \n",
        "    def feed(x, encoder, decoder, discriminator, optimizer):\n",
        "    \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            l_kl, l_rec, l_gen, l_dis = calculate_loss(x)\n",
        "            l_enc = l_kl + l_rec\n",
        "            l_dec = l_rec + l_gen\n",
        "\n",
        "        enc_grads = tape.gradient(l_enc, encoder.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(enc_grads, encoder.trainable_variables))\n",
        "\n",
        "        dec_grads = tape.gradient(l_dec, decoder.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(dec_grads, decoder.trainable_variables))\n",
        "\n",
        "        dis_grads = tape.gradient(l_dis, discriminator.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(dis_grads, discriminator.trainable_variables))\n",
        "\n",
        "        return l_kl.numpy(), l_rec.numpy(), l_gen.numpy(), l_dis.numpy()\n",
        "\n",
        "\n",
        "    def train(x, encoder, decoder, discriminator, optimizer):\n",
        "        l_kl, l_rec, l_gen, l_dis = 0., 0., 0., 0.\n",
        "        n = 0\n",
        "        for train_x in x:\n",
        "            a, b, c, d = feed(train_x, encoder, decoder, discriminator, optimizer)\n",
        "            l_kl += a\n",
        "            l_rec += b\n",
        "            l_gen += c\n",
        "            l_dis += d\n",
        "            n += 1\n",
        "        \n",
        "        return l_kl / n, l_rec / n, l_gen / n, l_dis / n\n",
        "    \n",
        "    \n",
        "    return encoder, decoder, discriminator, vae, train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLaqmlcxuy0O",
        "outputId": "cfd63e1e-da93-4f16-bebe-89207cc056e3"
      },
      "source": [
        "encoder, decoder, discriminator, vae, train = make_model()\n",
        "vae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 14, 14, 8)    208         encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 14, 14, 8)    32          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 7, 7, 16)     3216        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 7, 7, 16)     64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 784)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "z_mean (Dense)                  (None, 10)           7850        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "z_log_var (Dense)               (None, 10)           7850        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 10)           0           z_mean[0][0]                     \n",
            "                                                                 z_log_var[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Model)                 (None, 28, 28, 1)    14889       lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 34,109\n",
            "Trainable params: 34,061\n",
            "Non-trainable params: 48\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYXBaGIZXa8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8986e0b1cae540559c6648ccffc58c7f",
            "52e7df7a292b4a7c88cd9092ceea759f",
            "101fd3a8856f45988e6f2e506ea9e961",
            "9a3527b8f3834374ac9bbaeef67c7c57",
            "3649d5c0225b4899be3441cf4b6df88e",
            "3bd290dc640548779360c5dc7d4ab24f",
            "fe9c3c3e7e5a4c57ac18b98a31b1c57e",
            "e3a064da1474435bbb5bd9880d69e8fb"
          ]
        },
        "outputId": "8cf235b0-8939-4b90-d985-80cb860dcfd1"
      },
      "source": [
        "for epoch in tqdm(range(500)):\n",
        "    l = train(train_dataset, encoder, decoder, discriminator, k.optimizers.Adam(1e-4))\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print('\\n'+'kl_loss:', l[0], 'rec_loss:', l[1], 'gen_loss:', l[2], 'dis_loss:', l[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8986e0b1cae540559c6648ccffc58c7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "\n",
            "kl_loss: 0.00017770345023434078 rec_loss: 720.4487862723214 gen_loss: 1.5018533876964024 dis_loss: 2.0335034268242973\n",
            "\n",
            "kl_loss: 0.0001275919660526727 rec_loss: 720.4484950474331 gen_loss: 2.1360995837620327 dis_loss: 1.910234042576381\n",
            "\n",
            "kl_loss: 9.531033491449697e-05 rec_loss: 720.4478001185826 gen_loss: 2.1987831047603064 dis_loss: 1.9082642998014177\n",
            "\n",
            "kl_loss: 0.0001073502702638507 rec_loss: 720.4480085100446 gen_loss: 2.1966149636677335 dis_loss: 1.9106018934931075\n",
            "\n",
            "kl_loss: 0.0002137585759295949 rec_loss: 720.4483790806362 gen_loss: 2.202278872898647 dis_loss: 1.902589520386287\n",
            "\n",
            "kl_loss: 0.0002538183770541634 rec_loss: 720.4486101422991 gen_loss: 2.1943996735981535 dis_loss: 1.9135390537125723\n",
            "\n",
            "kl_loss: -6.919652223587036e-05 rec_loss: 720.4479989188058 gen_loss: 2.196435764857701 dis_loss: 1.9106150627136231\n",
            "\n",
            "kl_loss: 0.00011976782032953841 rec_loss: 720.4479823521206 gen_loss: 2.1961462702069965 dis_loss: 1.9111307161194937\n",
            "\n",
            "kl_loss: 0.00025988107622002384 rec_loss: 720.4480564662389 gen_loss: 2.1962267909731183 dis_loss: 1.9109786476407733\n",
            "\n",
            "kl_loss: 0.0001326971604222698 rec_loss: 720.447736467634 gen_loss: 2.1957976920264106 dis_loss: 1.9114634241376605\n",
            "\n",
            "kl_loss: -0.00016517118284744875 rec_loss: 720.4476728166852 gen_loss: 2.1965350355420794 dis_loss: 1.9102579491479057\n",
            "\n",
            "kl_loss: 8.195506608379738e-05 rec_loss: 720.4477861676897 gen_loss: 2.1966863666261944 dis_loss: 1.9101746950830731\n",
            "\n",
            "kl_loss: 0.00020002851129642554 rec_loss: 720.447798374721 gen_loss: 2.1971591745104107 dis_loss: 1.909655693599156\n",
            "\n",
            "kl_loss: 0.00014414073500250066 rec_loss: 720.44773210798 gen_loss: 2.195873488698687 dis_loss: 1.9106790542602539\n",
            "\n",
            "kl_loss: 0.00014738225477880666 rec_loss: 720.4477722167969 gen_loss: 2.1970719848360334 dis_loss: 1.9097996745790755\n",
            "\n",
            "kl_loss: -4.704509462629046e-07 rec_loss: 720.447815813337 gen_loss: 2.1967686244419644 dis_loss: 1.9101794583456857\n",
            "\n",
            "kl_loss: 0.00035417033692023586 rec_loss: 720.4477434430804 gen_loss: 2.1965279374803814 dis_loss: 1.910062643459865\n",
            "\n",
            "kl_loss: 0.0003810223873837718 rec_loss: 720.4478594098772 gen_loss: 2.1967005150658743 dis_loss: 1.9100818957601275\n",
            "\n",
            "kl_loss: -6.114641603614603e-06 rec_loss: 720.447811453683 gen_loss: 2.1981921877179826 dis_loss: 1.9086746181760514\n",
            "\n",
            "kl_loss: 0.00029602536066834415 rec_loss: 720.4478088378906 gen_loss: 2.1968682731900895 dis_loss: 1.9098163519586835\n",
            "\n",
            "kl_loss: 6.632230111530849e-05 rec_loss: 720.4476763044084 gen_loss: 2.1974873100008283 dis_loss: 1.9094929558890206\n",
            "\n",
            "kl_loss: 0.00012121268747640507 rec_loss: 720.447651890346 gen_loss: 2.1972988401140485 dis_loss: 1.9095866067068918\n",
            "\n",
            "kl_loss: 0.00020698979496955872 rec_loss: 720.4476344517299 gen_loss: 2.197010748726981 dis_loss: 1.9097439919199262\n",
            "\n",
            "kl_loss: 2.3049718999703016e-05 rec_loss: 720.4476841517857 gen_loss: 2.196320949281965 dis_loss: 1.9102215119770596\n",
            "\n",
            "kl_loss: 5.547427738617573e-05 rec_loss: 720.4476719447545 gen_loss: 2.1973945481436594 dis_loss: 1.9095539927482605\n",
            "\n",
            "kl_loss: 0.0001370735963324218 rec_loss: 720.4476588657924 gen_loss: 2.196989168439593 dis_loss: 1.9096821512494768\n",
            "\n",
            "kl_loss: 0.00022853860698108163 rec_loss: 720.4476370675224 gen_loss: 2.197052686555045 dis_loss: 1.9096928034509932\n",
            "\n",
            "kl_loss: -0.0001383802870155445 rec_loss: 720.4476318359375 gen_loss: 2.1972423008510042 dis_loss: 1.9096183708735874\n",
            "\n",
            "kl_loss: 0.00026551394922924896 rec_loss: 720.4476318359375 gen_loss: 2.197339858327593 dis_loss: 1.9095644286700657\n",
            "\n",
            "kl_loss: 0.00010177546979061195 rec_loss: 720.4476545061384 gen_loss: 2.1969834293637955 dis_loss: 1.9096738389560155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcBYTivSmlOO"
      },
      "source": [
        "m, n = 7,7\n",
        "iter_ = test_dataset.make_one_shot_iterator()\n",
        "x = iter_.get_next()\n",
        "reconstructions = vae.predict(x,steps=1)\n",
        "print(reconstructions.shape)\n",
        "for i in range(m):\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    for j in range(n):\n",
        "        plt.subplot(2, n,j +1)\n",
        "        plt.imshow(reconstructions[i*n + j, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, n,1 + j + n)\n",
        "        plt.imshow(x[i*n + j, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "    #plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6HNn6X5xdeK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv5ocjDXxdg-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhgW-ZvMxdj6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f73d-OkJxdmn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ1zZk7qxdqH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rygevfs_GdtY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXwrOltuGdy8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXJaRkjGd4U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji5xtcEXGd9w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9-Xk3qrGeDW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJXM2f6UGeJE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPOcSJdHGeRr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euFyW7MgGeW-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UbmuSJWGiLD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgWFa46GGiR5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQdToQnLGiZa"
      },
      "source": [
        "decoded_imgs = model.predict(x_test)\n",
        "\n",
        "# Use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}